---
title: 2025.3.10 学习内容
tags: Record
---

- 第二周课程内容

&#8226; 《一般拓扑学》- 拓扑子空间、紧性、连通性、连续函数

&#8226; 《模糊数学》- 模糊集合关系与运算、格（回顾离散数学知识）与代数系统

&#8226; 《试验设计》- 单因子试验设计与分析、区组设计

&#8226; 《可靠性统计》- 参数估计、区间估计、置信水平、枢轴量等（复习数理统计的知识点）



- 《机器学习理论引导》学习

&#8226; 第8章 遗憾界

1. 完全信息在线学习

   - 可行域 $W\subset \mathbb{R}^d $为凸集，第 $t$ 轮选择 $w_t \in W$，损失函数 $f_t$ 凸且可微，并产生损失 $f_t(w_t)$。
   - $regret= \sum_{t=1}^T f_t(w_t)-\min_{w\in W}\sum_{t=1}^T f_t(w)$.
     1. **在线梯度下降（$OGD$）算法**：$w_{t+1}= \Pi_W\Bigl(w_t - \eta_t\,\nabla f_t(w_t)\Bigr)$;当损失函数满足 $l$-Lipschitz，且可行域直径 $\Gamma$ 有界，则 $OGD$ 的遗憾可达 $\mathrm{Regret}_T = O(\sqrt{T})$.
     2.  $f_t$ **强凸：$O(\log T)$ 遗憾界**（强凸让离最优解越远时收敛越快，从而减少总损失）。

2. 赌博机在线学习

    &#8226; 多臂老虎机$(MAB)$ : 有 $K$ 个臂，每轮选一个臂获得随机奖励（期望未知），通过控制每个次优臂被选次数 $n_i^T$控制后悔变小。

   - 目标：在有限轮次内平衡探索（估计各臂均值）与利用（选择高奖励臂），最大化累计奖励。

   - $regret= T \mu_{i^*} - \sum_{t=1}^T \mu_{i_t}$
，其中 $i^*$ 为最优臂。

   - **$UCB$（上置信界）算法**

     1. **核心**：对每个臂维护“经验平均 + 不确定度项”，如
         $μ^i + \sqrt{\tfrac{2\ln\alpha}{n_i}}$。

     2. **选择规则**：每轮选 $UCB$ 值最高的臂。
     3. **理解**：未被充分探索的臂$n_i$ 小,会有更大置信区间，从而获得更多尝试机会。
     4. $regret$为 $O(\ln T)$.

